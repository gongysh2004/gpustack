# 调度器

aiMindServe 调度器负责将模型实例分配给工作节点。它根据以下因素做出决策：

- 工作节点的可用资源（GPU 内存、CPU 内存等）
- 模型实例的资源需求
- 工作节点的负载
- 工作节点的状态（健康、离线等）

## 调度策略

aiMindServe 使用以下调度策略：

1. **资源匹配**：调度器会检查工作节点的可用资源是否满足模型实例的资源需求。

2. **负载均衡**：调度器会尽量将模型实例均匀地分配到所有工作节点上。

3. **故障转移**：如果工作节点发生故障，调度器会将模型实例重新分配到其他工作节点。

4. **优先级**：调度器会根据模型实例的优先级进行调度。

## 调度过程

1. 当用户请求部署模型时，调度器会收到部署请求。

2. 调度器会检查所有工作节点的状态和资源情况。

3. 调度器会根据调度策略选择合适的工作节点。

4. 调度器会将模型实例部署到选定的工作节点上。

5. 调度器会监控模型实例的运行状态，如果发生故障，会进行故障转移。

## 配置

您可以通过以下方式配置调度器：

1. 在服务器配置文件中设置调度策略。

2. 通过 API 动态调整调度策略。

3. 通过 Web UI 查看调度状态和调整调度策略。

## 调度流程

### 过滤阶段

过滤阶段旨在将可用的工作节点或 GPU 缩小到符合特定标准的范围。主要涉及的策略包括：

- 标签匹配策略
- 状态策略
- 资源适配策略

#### 标签匹配策略

该策略根据为模型配置的标签选择器过滤工作节点。如果模型没有定义标签选择器，则考虑所有工作节点。否则，系统会检查每个工作节点的标签是否与模型的标签选择器匹配，只保留匹配的工作节点。

#### 状态策略

该策略根据工作节点的状态进行过滤，只保留处于 READY 状态的工作节点。

#### 资源适配策略

资源适配策略是调度系统中的关键策略，用于根据资源兼容性过滤工作节点或 GPU。该策略的目标是确保模型实例可以在选定的节点上运行，而不会超出资源限制。资源适配策略按以下顺序优先考虑候选节点：

- 单工作节点，单 GPU 完全卸载：识别单个工作节点上的单个 GPU 可以完全卸载模型的候选节点，这通常提供最佳性能。
- 单工作节点，多 GPU 完全卸载：识别单个工作节点上的多个 GPU 可以完全卸载模型的候选节点。
- 跨多个工作节点的分布式推理：识别跨多个工作节点的 GPU 组合可以处理完全或部分卸载的候选节点，仅在允许跨节点分布式推理时使用。
- 单工作节点部分卸载：识别单个工作节点上可以处理部分卸载的候选节点，仅在允许部分卸载时使用。
- 单工作节点，CPU：当没有可用的 GPU 时，系统将使用 CPU 进行推理，识别单个工作节点上内存资源充足的候选节点。

### 评分阶段

评分阶段评估过滤后的候选节点，对其进行评分以选择最佳部署位置。主要涉及的策略包括：

- 放置策略

#### 放置策略

- Binpack（装箱）

  该策略旨在将尽可能多的模型实例"打包"到最少数量的"箱子"（例如，工作节点/GPU）中，以优化资源利用率。目标是最大限度地减少使用的箱子数量，同时最大化资源效率，确保每个箱子尽可能高效地填充，而不超过其容量。模型实例被放置到剩余空间最少的箱子中，以最小化每个箱子中的剩余容量。

- Spread（分散）

  该策略寻求将多个模型实例尽可能均匀地分布在不同工作节点上，提高系统容错性和负载均衡。 
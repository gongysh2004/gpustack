# 模型文件管理

aiMindServe 允许管理员下载和管理模型文件。

## 添加模型文件

aiMindServe 目前支持来自 [Hugging Face](https://huggingface.co)、[ModelScope](https://modelscope.cn)、[Ollama](https://ollama.com/library) 以及本地路径的模型。要添加模型文件，请进入 `资源` 页面并点击 `模型文件` 标签页。

### 添加 Hugging Face 模型

1. 点击 `添加模型文件` 按钮，并在下拉菜单中选择 `Hugging Face`。
2. 使用左上角的搜索栏按名称查找模型，例如 `Qwen/Qwen2.5-0.5B-Instruct`。如只需查找 GGUF 模型，可勾选 `GGUF` 复选框。
3. _(可选)_ 对于 GGUF 模型，可在 `可用文件` 中选择所需的量化格式。
4. 选择目标工作节点以下载模型文件。
5. _(可选)_ 指定 `本地目录`，将模型下载到自定义路径，而不是 GPUStack 缓存目录。
6. 点击 `保存` 按钮。

### 添加 ModelScope 模型

1. 点击 `添加模型文件` 按钮，并在下拉菜单中选择 `ModelScope`。
2. 使用左上角的搜索栏按名称查找模型，例如 `Qwen/Qwen2.5-0.5B-Instruct`。如只需查找 GGUF 模型，可勾选 `GGUF` 复选框。
3. _(可选)_ 对于 GGUF 模型，可在 `可用文件` 中选择所需的量化格式。
4. 选择目标工作节点以下载模型文件。
5. _(可选)_ 指定 `本地目录`，将模型下载到自定义路径，而不是 GPUStack 缓存目录。
6. 点击 `保存` 按钮。


### 添加本地路径模型

你可以添加本地路径下的模型。路径可以是目录（如 Hugging Face 模型文件夹）或文件（如 GGUF 模型），需位于工作节点上。

1. 点击 `添加模型文件` 按钮，并在下拉菜单中选择 `本地路径`。
2. 输入 `模型路径`。
3. 选择目标工作节点。
4. 点击 `保存` 按钮。

## 重试下载

如果模型文件下载失败，你可以重试：

1. 进入 `资源` 页面并点击 `模型文件` 标签页。
2. 找到状态为错误的模型文件。
3. 点击 `操作` 列的省略号按钮，选择 `重试下载`。
4. GPUStack 会尝试重新从指定源下载模型文件。

## 部署模型

可以从模型文件部署模型。由于模型存储在特定工作节点上，aiMindServe 会使用 `worker-name` 作为选择器，确保调度到正确节点。

1. 进入 `资源` 页面并点击 `模型文件` 标签页。
2. 找到你要部署的模型文件。
3. 点击 `操作` 列的 `部署` 按钮。
4. 检查或调整 `名称`、`副本数` 及其他部署参数。
5. 点击 `保存` 按钮。

## 删除模型文件

1. 进入 `资源` 页面并点击 `模型文件` 标签页。
2. 找到你要删除的模型文件。
3. 点击 `操作` 列的省略号按钮，选择 `删除`。
4. _(可选)_ 勾选 `同时从磁盘删除文件`。
5. 点击 `删除` 按钮确认。 